{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1df3d3",
   "metadata": {},
   "source": [
    "# Differential Privacy in Machine Learning\n",
    ":label:`chap_dp`\n",
    "\n",
    "\n",
    "**Yu-Xiang Wang** (*UC Santa Barbara / Amazon*)\n",
    "\n",
    "\n",
    "Machine learning (ML) methods need training datasets to work. Access to task-specific datasets is often taken for granted in typical ML applications. In sensitive applications such as those in healthcare, finance and legal context, however, access to the datasets involving human subjects has been increasingly limited due to various privacy concerns. \n",
    "\n",
    "Recent regulations such as the General Data Privacy Regulation (GDPR) in the European Union and the California Consumer Privacy Act (CCPA) have posed steep obstacles for the industry to have access to (their own!) user data for research and product using machine learning. Even in the seemingly benevolent applications where Personal Identifiable Information (PII) is removed from data and only aggregate statistics are revealed, there had been practical attacks that can confidently re-identify individuals or even reconstruct their sensitive data.\n",
    "\n",
    "Differential privacy (DP) (Dwork et al., 2006) is one of the most promising approaches towards addressing the privacy challenges in the era of artificial intelligence and big data. It is a formal mathematical definition that provides provable guarantees in addressing the aforementioned privacy concerns, thus enabling machine learning for sensitive applications. Recently, DP is going through an exciting transformation from a theoretical construct into a practical technology. Both the private and public sectors are investing heavily in differential privacy research and building them into products.\n",
    "\n",
    "In this chapter, we will cover the basics of differential privacy and with a focus on its applications to machine learning. By studying this chapter, you will develop sufficient theoretical understanding of DP to correctly interpret its guarantees and gain working hands-on experience of incorporating DP for machine learning applications using open source packages such as ```autodp``` and ```opacus```. Moreover, you will learn to distinguish when DP is a good fit for each application and when not, as well as to explain the semantics of DP to people with variously level of technical backgrounds. \n",
    "\n",
    "One unique aspect of the D2L's DP chapter comparing to existing treatments to DP and machine learning with DP is that you will be provided with runnable code blocks with actual ```autodp``` implementation of the DP mechanisms, which you can plug into your own application. The implementation will remain up to date and allow your application to get the benefit from the latest and greatest in modern DP accounting. \n",
    "\n",
    " \n",
    "\n",
    "```toc\n",
    ":maxdepth: 2\n",
    "\n",
    "privacy_challenges\n",
    "dp_definition\n",
    "dp_mechanisms\n",
    "dp_composition\n",
    "autodp\n",
    "dpml_intro\n",
    "dp_linear_regression\n",
    "dp_logistic_regression\n",
    "noisygd\n",
    "noisysgd_dpdl\n",
    "hyperparameters\n",
    "future_trend\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
